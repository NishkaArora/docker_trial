{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "859c3a80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/nishka/training_logs/exp/training/gpu0workerstrain_simple_vector_map_model/2023.07.14.19.48.58/checkpoints/epoch=9.ckpt'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import hydra\n",
    "import torch\n",
    "\n",
    "# Create a temporary directory to store the cache and experiment artifacts\n",
    "# SAVE_DIR = Path(tempfile.gettempdir()) / 'tutorial_nuplan_framework'  # optionally replace with persistent dir\n",
    "SAVE_DIR = Path('/home/nishka')\n",
    "EXPERIMENT = 'training_logs/exp/training'\n",
    "JOB_NAME = 'gpu0workerstrain_simple_vector_map_model'\n",
    "LOG_DIR = SAVE_DIR / EXPERIMENT / JOB_NAME\n",
    "\n",
    "# Get the checkpoint of the trained model\n",
    "last_experiment = sorted(os.listdir(LOG_DIR))[-1]\n",
    "train_experiment_dir = sorted(LOG_DIR.iterdir())[-1]\n",
    "checkpoint = sorted((train_experiment_dir / 'checkpoints').iterdir())[-1]\n",
    "MODEL_PATH = str(checkpoint)\n",
    "MODEL_PATH_cfg = str(checkpoint).replace(\"=\", \"\\=\")\n",
    "MODEL_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cae7e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name of the experiment\n",
    "EXPERIMENT = 'Simple_VMM_Experiment'\n",
    "\n",
    "### Not used ###\n",
    "CHALLENGE = 'open_loop_boxes'  # [open_loop_boxes, closed_loop_nonreactive_agents, closed_loop_reactive_agents]\n",
    "DATASET_PARAMS = [\n",
    "    'scenario_builder=nuplan_mini',  # use nuplan mini database\n",
    "    'scenario_filter=all_scenarios',  # initially select all scenarios in the database\n",
    "    'scenario_filter.scenario_types=[near_multiple_vehicles, on_pickup_dropoff, starting_unprotected_cross_turn, high_magnitude_jerk]',  # select scenario types\n",
    "    'scenario_filter.num_scenarios_per_type=10',  # use 10 scenarios per scenario type\n",
    "]\n",
    "# Location of path with all simulation configs\n",
    "CONFIG_PATH = '../nuplan/planning/script/config/simulation'\n",
    "CONFIG_NAME = 'default_simulation'\n",
    "##################\n",
    "\n",
    "# Initialize configuration management system\n",
    "hydra.core.global_hydra.GlobalHydra.instance().clear()  # reinitialize hydra if already initialized\n",
    "hydra.initialize(config_path=CONFIG_PATH)\n",
    "\n",
    "# Compose the configuration\n",
    "cfg = hydra.compose(config_name=CONFIG_NAME, overrides=[\n",
    "    f'experiment_name={EXPERIMENT}',\n",
    "    f'group={SAVE_DIR}',\n",
    "    'planner=ml_planner',\n",
    "    'model=simple_vector_model',\n",
    "    'planner.ml_planner.model_config=${model}',  # hydra notation to select model config\n",
    "    f'planner.ml_planner.checkpoint_path={MODEL_PATH_cfg}',  # this path can be replaced by the checkpoint of the model trained in the previous section\n",
    "    f'+simulation={CHALLENGE}',\n",
    "    *DATASET_PARAMS,\n",
    "])\n",
    "planner_cfg = cfg.planner.ml_planner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ca07dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nuplan.planning.script.builders.model_builder import build_torch_module_wrapper\n",
    "from nuplan.planning.training.modeling.lightning_module_wrapper import LightningModuleWrapper\n",
    "\n",
    "torch_module_wrapper = build_torch_module_wrapper(planner_cfg.model_config)\n",
    "model = LightningModuleWrapper.load_from_checkpoint(MODEL_PATH, model=torch_module_wrapper).model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc1bcb55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorMapSimpleMLP(\n",
       "  (vectormap_mlp): Sequential(\n",
       "    (0): Linear(in_features=4, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "  )\n",
       "  (ego_mlp): Sequential(\n",
       "    (0): Linear(in_features=15, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "  )\n",
       "  (agent_mlp): Sequential(\n",
       "    (0): Linear(in_features=40, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "  )\n",
       "  (_mlp): Sequential(\n",
       "    (0): Linear(in_features=384, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=48, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b29988a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from typing import cast\n",
    "from nuplan.planning.training.preprocessing.features.agents import Agents\n",
    "from nuplan.planning.training.preprocessing.features.trajectory import Trajectory\n",
    "from nuplan.planning.training.preprocessing.features.vector_map import VectorMap\n",
    "\n",
    "with open('examples/agents', 'rb') as pick:\n",
    "    agents = pickle.load(pick)\n",
    "    agents = Agents(ego=agents['ego'], agents=agents['agents'])\n",
    "\n",
    "with open('examples/vector_map', 'rb') as pick:\n",
    "    vmap = pickle.load(pick)\n",
    "    vmap = VectorMap(coords=vmap['coords'], lane_groupings=vmap['lane_groupings'],\n",
    "                    multi_scale_connections=vmap['multi_scale_connections'],\n",
    "                    on_route_status=vmap['on_route_status'],\n",
    "                    traffic_light_data=vmap['traffic_light_data'])\n",
    "\n",
    "# with open('examples/trajectory', 'rb') as pick:\n",
    "#     traj = pickle.load(pick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb65f8e8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Type must be a sub-type of ndarray type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m      3\u001b[0m features \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvector_map\u001b[39m\u001b[38;5;124m'\u001b[39m: vmap, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124magents\u001b[39m\u001b[38;5;124m'\u001b[39m: agents}\n\u001b[0;32m----> 5\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/nuplan-devkit/nuplan/planning/training/modeling/models/simple_vector_map_model.py:136\u001b[0m, in \u001b[0;36mVectorMapSimpleMLP.forward\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m    133\u001b[0m list_list_tensor_inputs: Dict[\u001b[38;5;28mstr\u001b[39m, List[List[torch\u001b[38;5;241m.\u001b[39mTensor]]] \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m# Run the core logic of the model\u001b[39;00m\n\u001b[0;32m--> 136\u001b[0m output_tensors, output_list_tensors, output_list_list_tensors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscriptable_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlist_tensor_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlist_list_tensor_inputs\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;66;03m# Unpack the model's output\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrajectory\u001b[39m\u001b[38;5;124m\"\u001b[39m: Trajectory(data\u001b[38;5;241m=\u001b[39moutput_tensors[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrajectory\u001b[39m\u001b[38;5;124m\"\u001b[39m])}\n",
      "File \u001b[0;32m~/nuplan-devkit/nuplan/planning/training/modeling/models/simple_vector_map_model.py:172\u001b[0m, in \u001b[0;36mVectorMapSimpleMLP.scriptable_forward\u001b[0;34m(self, tensor_data, list_tensor_data, list_list_tensor_data)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# map and agent feature have different size across batch so we use per sample feature extraction\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sample_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(batch_size):\n\u001b[0;32m--> 172\u001b[0m     sample_ego_feature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mego_mlp(\u001b[43mego_past_trajectory\u001b[49m\u001b[43m[\u001b[49m\u001b[43msample_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    173\u001b[0m     ego_feature\u001b[38;5;241m.\u001b[39mappend(torch\u001b[38;5;241m.\u001b[39mmax(sample_ego_feature, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;66;03m# Use reshape() throughout insead of view() because incoming tensors may not be contiguous\u001b[39;00m\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;66;03m#  (e.g. if being called from torchscript)\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Type must be a sub-type of ndarray type"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "features = {'vector_map': vmap, 'agents': agents}\n",
    "\n",
    "model.forward(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007a986a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
